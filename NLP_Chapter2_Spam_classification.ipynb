{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff4ed0c",
   "metadata": {},
   "source": [
    "## 1. LSTM 모델을 이용한 NLP Classification (스팸메일분류기) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416863f6",
   "metadata": {},
   "source": [
    "### 1-1. Fully Connected Layer (FCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614673b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3013bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN (FCL) pytorch로 구성\n",
    "# nn structure: input -> fc1 -> fc2 -> output\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, num_output, input_size, hidden_size, device):\n",
    "        super(ANN, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        #linear 모델 사용\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.outlayer = nn.Linear(hidden_size, num_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #relu() if input is <=0 => return 0\n",
    "        h = self.fc1(x).relu()\n",
    "        h = self.fc2(h).relu()\n",
    "        predict = self.outlayer(h)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d68af",
   "metadata": {},
   "source": [
    "### 1-2. LSTM for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "746486e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure: input (정수 인코딩된 결과) -> Embed Layer (word2vec역할) -> LSTM\n",
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, num_output, size_vocab, dim_embed, hidden_size, linear_size, num_layers, device):\n",
    "        super(LSTM_net, self).__init__()\n",
    "        self.device = device #GPU\n",
    "        self.num_output = num_output #1 (스팸인지 아닌지 구분하는 목적이기 때문에)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # (단어갯수,임베딩차원)\n",
    "        self.embed = nn.Embedding(size_vocab, dim_embed)\n",
    "        \n",
    "        #layer 양이 많아질 수록 복잡해짐, dropout: 정규화목적, bidirection/singledirection선택\n",
    "        self.lstm = nn.LSTM(input_size = dim_embed, hidden_size = hidden_size,\n",
    "                           num_layers = num_layers, dropout = 0.3, bidirectional = True)\n",
    "        # 분류 문제에 사용할 것이기에 lstm 다음에 fcl 구현 이 후 output layer\n",
    "        self.fclayer = nn.Linear(hidden_size, linear_size)\n",
    "        self.outlayer = nn.Linear(linear_size, num_output)\n",
    "    \n",
    "    # x: 정수인코딩 (batch_size, seq_len)\n",
    "    def forward(self, x):\n",
    "        scaler = 2 if self.lstm.bidirectional == True else 1\n",
    "        emb = self.embed(x) #word2vec 결과 (batch_size, seq_len, dim_embed)\n",
    "        \n",
    "        # hidden state 초기화 (num_layer *scaler, batch_size, hidden_size(LSTM의 hidden layer size))\n",
    "        h_state = Variable(torch.zeros(self.num_layers * scaler, emb.size(0),\n",
    "                                      self.hidden_size, requires_grad = True)).to(self.device)\n",
    "        # cell state 초기화 \n",
    "        c_state = Variable(torch.zeros(self.num_layers * scaler, emb.size(0),\n",
    "                                      self.hidden_size, requires_grad = True)).to(self.device)\n",
    "        \n",
    "        #lstm 에서는 em: [seq_len, batch, dim_embed] 로 들어가야하므로 transpose 이용\n",
    "        lstm_out, (h, c) = self.lstm(emb.transpose(1,0), (h_state, c_state))\n",
    "        \n",
    "        # 마지막 시간의 hidden layer만 사용할 것이기에 -1 index로 호출\n",
    "        h = h[-1]\n",
    "        h = self.fclayer(h).relu()\n",
    "        #최종  predict 차원 [batch, num_output]\n",
    "        predict = self.outlayer(h)\n",
    "        \n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eeb07c",
   "metadata": {},
   "source": [
    "### 1-3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f60e6137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5796 entries, 0 to 5795\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5796 non-null   object\n",
      " 1   target  5796 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n",
       "1  From gort44@excite.com Mon Jun 24 17:54:21 200...       1\n",
       "2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1\n",
       "3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1\n",
       "4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"spam_assassin.csv\") #kaggle에 있는 open dataset 이용\n",
    "display(data.info(), data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acee180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: 5796\n"
     ]
    }
   ],
   "source": [
    "# 토큰화\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data = data.dropna().reset_index(drop=True) #missing variable 확인\n",
    "token_text = []\n",
    "for i in range(len(data)):\n",
    "    token = word_tokenize(data.iloc[i,0])\n",
    "    token_stop_text = []\n",
    "    for w in token:\n",
    "        if w not in stop_words:\n",
    "            token_stop_text.append(w)\n",
    "    token_text.append(token_stop_text)\n",
    "print('After cleaning:', len(token_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bddbd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165354\n"
     ]
    }
   ],
   "source": [
    "#  정수 인코딩\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(token_text)\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fddebda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 181, 6, 59, 47, 44, 225, 69713, 12, 79, 3, 2, 181, 6, 59, 1, 68, 3, 78, 6, 179, 15, 3, 16, 8, 16, 14, 33, 13, 7, 160, 8, 48, 7, 25, 18, 69714, 2, 36, 6, 16, 1, 10, 47, 5, 225, 44, 12, 69715, 61, 8, 102, 7, 15, 3, 214, 14, 33, 13, 16, 94, 8, 90, 7, 36, 6, 16, 8, 91, 7, 10, 47, 5, 225, 44, 12, 69716, 28, 8, 60, 7, 15, 3, 119, 8, 220, 6, 119, 14, 508, 13, 7, 58, 8, 64, 7, 25, 18, 69717, 2, 582, 6, 55, 1, 10, 159, 5, 321, 44, 12, 69718, 28, 15, 3, 412, 8, 220, 6, 16, 14, 33, 13, 7, 119, 8, 193, 7, 25, 18, 69719, 10, 159, 5, 321, 44, 12, 69720, 28, 424, 3, 119, 3, 472, 220, 6, 16, 14, 33, 13, 514, 412, 15, 3, 8358, 8, 8358, 14, 18035, 13, 7, 119, 8, 193, 7, 25, 18, 69721, 2, 107, 6, 59, 1, 10, 159, 5, 321, 44, 12, 43445, 28, 15, 3, 69722, 8, 14, 69723, 13, 16372, 7, 8358, 25, 8, 237, 1048, 17, 67, 7, 18, 69724, 107, 6, 59, 10, 159, 5, 321, 44, 12, 69725, 28, 15, 3, 8, 13528, 6, 16, 7, 6377, 8, 11791, 7, 18, 69726, 107, 6, 59, 10, 159, 5, 321, 44, 12, 43446, 28, 63, 3, 159, 5, 321, 44, 12, 69727, 28, 35, 3, 3058, 6058, 2, 8047, 6, 6378, 1, 49, 3, 107, 1321, 82, 2, 107, 6, 59, 1, 65, 3, 146, 3, 14, 107, 13, 4554, 18036, 2110, 1413, 18037, 8, 7147, 7, 76, 3, 2, 69728, 6, 6377, 1, 1391, 3, 107, 1321, 82, 2, 107, 6, 59, 1, 256, 3, 2, 32195, 6, 2909, 1, 97, 3, 96, 70, 3, 101, 10, 209, 536, 3, 545, 466, 3, 3469, 221, 3, 2, 32195, 6, 2909, 1, 10, 6059, 6, 6060, 75, 5, 44, 173, 5, 12, 43447, 28, 110, 3, 181, 6, 59, 134, 3, 181, 6, 59, 138, 3, 502, 118, 3, 114, 130, 3, 243, 156, 207, 86, 204, 2, 560, 1, 137, 3, 107, 6, 59, 227, 75, 5, 44, 173, 5, 12, 43447, 28, 16373, 16374, 5, 5201, 5, 3058, 986, 3, 1, 5656, 158, 1764, 689, 43448, 484, 5, 765, 784, 1, 5, 748, 377, 18038, 10925, 11, 1, 343, 1249, 18038, 43449, 573, 215, 26, 2424, 5, 29, 454, 911, 43450, 18038, 29, 454, 2910, 323, 21154, 877, 108, 1, 3277, 29, 158, 5, 11792, 216, 384, 1868, 27, 1, 5544, 690, 10, 9, 7, 7148, 108, 231, 544, 5, 29, 440, 1519, 11, 67, 11, 29, 16375, 1238, 491, 598, 643, 248, 784, 420, 43451, 24588, 6061, 11, 54, 11, 539, 43452, 784, 11793, 1823, 311, 29, 1355, 504, 1823, 562, 784, 216, 489, 51, 1612, 1392, 11, 2335, 5, 51, 234, 1250, 2299, 108, 1, 943, 986, 8359, 294, 4037, 26, 527, 689, 1594, 1, 3766, 356, 11, 1306, 5, 29, 242, 11, 105, 511, 2022, 29, 242, 24589, 12501, 690, 10419, 5, 32196, 694, 69729, 69730, 30, 29, 325, 8359, 1238, 1220, 309, 8, 8048, 11, 12502, 7708, 1536, 1238, 8, 7, 294, 8709, 7, 29, 242, 234, 511, 1823, 3352, 2774, 4038, 20, 3, 69731, 11, 69, 3664, 158, 81, 717, 413, 294, 10926, 503, 24590, 4039, 924, 11794, 2863, 2864, 765, 1127, 13529, 12503, 9916, 8, 21155, 7, 108, 3058, 9, 3058, 6058, 2, 8047, 6, 6378, 1, 3098, 7709, 3, 46, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 46, 16376, 69732, 1608, 481, 5, 43453, 5, 72, 207, 5, 1422, 1108, 3, 3386, 5, 3386, 5, 3386, 6377, 69733, 235, 481, 5, 69734, 5, 67, 571, 5, 1422, 1108, 3, 13530, 5, 13531, 5, 3386, 9, 243, 156, 207, 86, 204, 3, 107, 6, 59, 20, 3, 468, 8, 449, 7, 459, 165, 11, 82, 480, 3, 486, 6, 59]\n"
     ]
    }
   ],
   "source": [
    "text_encoded = tokenizer.texts_to_sequences(token_text)\n",
    "#첫번째 메일에대한 정수인코딩결과 예시로 확인\n",
    "print(text_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9146465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 Label: spam 인 경우 1 아니면 0\n",
    "text_label = np.array(data.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90a0710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5796,)\n",
      "(5796,)\n"
     ]
    }
   ],
   "source": [
    "# padding 및 데이터 자르기\n",
    "print(np.shape(text_encoded))\n",
    "print(np.shape(text_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68072a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15067\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "for w in text_encoded:\n",
    "    if len(w) >= maxlen:\n",
    "        maxlen = len(w)\n",
    "print(maxlen) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7ef9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5796, 100)\n"
     ]
    }
   ],
   "source": [
    "max_len = 100 #너무 길어서 임의로 100단어까지만 설정\n",
    "rowdata = []\n",
    "for w in text_encoded:\n",
    "    if len(w) >= max_len:\n",
    "        rowdata.append(w[:max_len])\n",
    "    else:\n",
    "        rowdata.append(np.pad(w, (0, max_len), 'constant', constant_values = 0)[:max_len])\n",
    "text_padded = np.concatenate(rowdata, axis = 0).reshape(-1, max_len)\n",
    "print(np.shape(text_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eb0c79",
   "metadata": {},
   "source": [
    "> 이메일은 보통 다수의 문장으로 이루어져있기 때문에 샘플의 길이가 길 수 있음. </br>\n",
    "따라서 maxlen을 설정하여 이 수 이하의 토큰을 가진 이메일은 pdding, 이상의 토큰을 가진 이메일은 나머지를 버림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d2fbe",
   "metadata": {},
   "source": [
    "### 1-4. 학습\n",
    "5000개 training 500개 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3623a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch import LongTensor as LT\n",
    "from torch import FloatTensor as FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec622c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generate_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, xdata, ydata, device):\n",
    "        self.x_data = xdata\n",
    "        self.y_data = ydata\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #정수 인코딩 해서 LongTensor를 사용함\n",
    "        x = LT(self.x_data[idx]).to(self.device)\n",
    "        y = LT(self.y_data[idx]).to(self.device)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6475caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 생성\n",
    "# x (input) : text_padded [5796,100] seq_len\n",
    "# y (label): text_labeled [5796, 1] (1또는 0으로 이루어짐)\n",
    "\n",
    "dataset = Generate_Dataset(text_padded[:5000, :], text_label[:5000].reshape([-1, 1]), device)\n",
    "trainset, testset = random_split(dataset, [4500, 500])\n",
    "# 학습하기 쉽도록 dataloader 를 이용\n",
    "train_loader = DataLoader(trainset, batch_size = 256, shuffle = True)\n",
    "\n",
    "#test는 한번에 할꺼라서 batch_size=500으로 하고 셔플하지않음\n",
    "test_loader = DataLoader(testset, batch_size = 500, shuffle = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c024398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Netword and Optimizer\n",
    "# output: binary classification을 one hot encoding 인 [1,0], [0,1]로 가져오려하기 때문에\n",
    "lstm_net = LSTM_net(num_output = 2, size_vocab = len(tokenizer.word_index), dim_embed = 64,\n",
    "                   hidden_size = 64, linear_size = 64, num_layers = 1, device = device)\n",
    "optimizer = torch.optim.Adam(lstm_net.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f21c052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:06<00:00,  2.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0054, grad_fn=<NllLossBackward0>)\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:06<00:00,  2.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9930e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:06<00:00,  2.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0165e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3614e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.1700e-06, grad_fn=<NllLossBackward0>)\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2639e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0264e-05, grad_fn=<NllLossBackward0>)\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0074, grad_fn=<NllLossBackward0>)\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 18/18 [00:07<00:00,  2.49batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0043, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Session\n",
    "from tqdm import tqdm\n",
    "for epoch in range(10):\n",
    "    print('Epoch', epoch)\n",
    "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
    "        for x, y in tepoch:\n",
    "            predict = lstm_net(x)\n",
    "            # ravel() 이용하여 행렬의 불필요한 차원을 제거함\n",
    "            loss = torch.nn.functional.cross_entropy(predict, y.ravel())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcdfb9c",
   "metadata": {},
   "source": [
    "#### 1-5. Test the Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2eb12d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  3.39batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477 out of 500, accuracy is  95.39999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(test_loader, unit = 'batch') as tepoch:\n",
    "    for x, y in tepoch:\n",
    "        # predict 차원 [500,2] -> 1차원에 관해 argmax 하면 큰 값 반환하여 [500,1] 반환\n",
    "        predict = lstm_net(x).argmax(1).detach().numpy()\n",
    "        answer = y.ravel().detach().numpy()\n",
    "score = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == answer[i]:\n",
    "        score += 1\n",
    "print(score, 'out of 500, accuracy is ', score/500*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40bf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
